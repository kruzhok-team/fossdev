# Менеджеры пакетов

Мы уже умеем размещать свой код на платформах типа GitHub, для того чтобы контролировать версию кода и иметь возможность взять код себе на машину локально, отправить свои правки, получать красивую визуализацию коммитов, а так же получать обратную связь от других разработчиков в виде issue, fork, merge request и так далее.Попробуем теперь воспользоваться кодом не как программисты-разработчики, а как программисты-пользователи. Да, каждый раз когда мы пишем:

```python
import lib_name
lib_name.do_something()
```

Мы уже умеем устанавливать пакет в связке pip+git(PASTE_LINK).Мы являемся пользователем функции `do_something()` из библиотеки `lib_name`. Как же нам получить do_somethig() там где мы пишем код и воспользоваться ей. Рассмотрим варианты, которыми на самом деле пользуются люди и потом, рассмотрим как сделать это правильно.


## Ctrl-C/Ctrl-V
Первый, наивный, способ это просто скопировать функцию себе и вызвать там где нужно (не делайте так).

Почему это плохо:

* теряется поддержка. Если разработчики найдут проблему в коде и устранят его мы не получим эти изменения, если не находимся в режиме мониторинга версий этого пакета.
* тянем кучу другого кода. Скорее всего у Вас даже не получиться так просто скопировать отдельную функцию, так как она использует другой код из этого пакета.
* теряется контроль зависимостей. Если для работы функций необходима другая библиотека определенной версии, это никак не отображается в коде, `import matplotlib` подключит ту библиотеку, которая установлена в окружении. Установка `pip install matplotlib` так же ничего не даст - будет установлена последняя версия библиотеки `matplotlib`. Правильная версия библиотеки должна содержаться в правильно структурированном репозитории, и чтобы ее найти нужно совершить дополнительное действие.
* нет возможность запустить тесты. Как правило в библиотеках содержаться тесты, которые можно запустить и проверить все ли корректно работает именно на этой машине. Просто копируя функцию мы не подтягиваем автоматически тесты.

## Клонируем и указываем путь через sys
Мы можем сделать клон репозитория:

```bash
git clone url
```
и установить все необходимые библиотеки используемые в проекте, в том случае, если таковые имеются. Для этого в репозитории, помимо кода можно найти файл `requirements.txt`, который предназначен для перечисления названий пакетов (библиотек) с указанием их версий. Таким образом, вы сможете использовать точные версии всех библиотек которыми пользовался разработчик. После того как вы склонировали репозиторий, в котором присутствует файл `requirements.txt`, вам следует установить перечисленные в нем библиотеки. Это можно выполнив используя менеджер пакетов `pip` командой:

`pip install -r requirements.txt`

Если нам повезет, там будут указаны версии библиотек, для которых разработчик тестировал работоспособность этого пакета. Так же мы можем прогнать тесты и убедиться что все работает как надо. После этого мы можем указать путь до библиотеки прямо в коде (актуально для python 3.5+):

```python
from importlib.util import (spec_from_file_location, 
                            module_from_spec)
import sys
spec = spec_from_file_location("module.name", "/path/to/my_package/my_module.py")
foo = module_from_spec(spec)
sys.modules["module.name"] = foo
spec.loader.exec_module(foo)
foo.MyClass()
```
    
или так:

```python
import sys
sys.path.append("/path/to/my_package")
import my_module
my_module.MyClass()
```

Уже лучше, но по-прежнему мы должны помнить проверять новые версии, процесс установки полностью ручной, а то, что мы написали в коде выглядит как костыль. Мы также можем добавить путь к пакету в `PYTHONPATH` иcпользуя `bash`:

```bash
export PYTHONPATH='/path/to/my_package'
```

Проверить, что переменная установилась можно вызвав команду `echo $PYTHONPATH`. После этого можно запустить интерпретатор питона и проверить что все работает, и что путь уже добавлен в `sys.path` 


## Ставим через pip используя git репозиторий

Мы добрались до более принятых способов управления зависимостями. Здесь мы уже используем `pip` и публично доступный репозиторий на GitHub для того, чтобы установить пакет. Примечание: мы его использовали в предыдущем пункте, но чтобы поставить зависимости устанавливаемой библиотеки, а не саму библиотеку.

Прежде чем мы перейдем к тому способу которым мы привыкли пользоваться:

```bash
pip install lib_name
```

Проговорим еще раз что существует такой способ, если Вы пропустили предыдущий урок, вернитесь и посмотрите что должно содержаться в проекте для того чтобы другие разработчики могли им воспользоваться. Не для всех языков программирования есть аналог `pip`, а понимание того, что в репозитории может содержать вся необходимая информация для того, чтобы установить/собрать библиотеку поможет легче найти решение проблеме установки для других языков.

## Немного про pip

Для инфраструктуры `python` менеджер пакетов `pip` является стандартом де факто, хотя появился с текущим именем не так [давно](https://ianbicking.org/blog/2008/10/pyinstall-is-dead-long-live-pip.html). Концепция менеджеров пакетов удобна для программиста, поэтому некоторые языки программирования и фреймворки реализуют ее для управления зависимостями: 


  * JavaScript: npm 
  * Ruby: gem,
  * .NET: NuGet

Для С++ существует проекты, которые направлены на решение этой проблемы:

  * [bpt](https://github.com/vector-of-bool/dds)
  * [cpm](http://www.cpm.rocks/)
  * [conan](https://conan.io/)
  * [poac](https://github.com/poacpm/poac)
  * [pacm](http://sourcey.com/pacm/)
  * [spack](https://spack.io)
  * [buckaroo](http://buckaroo.pm)
  * [hunter](https://github.com/ruslo/hunter)
  * [vcpkg](https://github.com/Microsoft/vcpkg)

В python так же существуют альтернативы `pip`, об одной из них мы поговорим ниже. Что же делает менеджер пакетов. 

Первый очевидный ответ: он кладет (а перед этим еще и скачивает их сам из сети) файлы библиотеки в правильное место: там где его сможет найти язык программирования чтобы импортировать.

Второе свойство менеджера пакетов: он хранит историю версий библиотеку, так чтобы могли установить нужную нам. *Примечание: не путайте версию библиотеки и версию в плане ссылки на конкретный коммит в git; не каждый коммит ведет к обновлению версии библиотеки в менеджере проектов*. Кроме того, менеджер проектов знает какие зависимости нужны именно этой версии библиотеки, таким образом у нас есть дерево зависимостей.

Третье: менеджер проектов дает возможность прогнать тесты при установке, так чтобы мы были уверены, что сделали все возможное, чтобы получить работающую библиотеку. При этом никто не гарантирует что тесты полностью покрывают все возможные ситуации, но часть из них точно, и это всегда неплохая идея проверить хотя бы их.


## Делаем свою библиотеку пакетом. `pip`

Когда нам нужна функциональность какой-либо библиотеки в Python, скорее всего мы ставим ее через pip:

```bash
pip install lib_name
```

Когда мы это делаем, `pip` просматривает публичный репозиторий пакетов Python Package Index (PyPI). Мы так же можем [хостит](https://packaging.python.org/en/latest/guides/hosting-your-own-index/) зеркало PyPI, если нам это для чего-то нужно. Если `lib_name` находится в PyPI будет выполнена попытка установки. В PyPI расположен сам пакет, но в чем же отличие от установки через связку `pip+git`. Библиотека может распространяться в виде исходных текстовых файлов **Source Distribution (sdist)** или собранных файлов **Built Distribution (bdist)**. Мы будем использовать `sdist` и `bdist` далее по тексту. 

Процесс создания sdist проще чем bdist, и на самом деле мы уже это проделывали. Для этого вида нужно чтобы весь исходный код, а так же другие необходимые файлы были собраны в одном месте. Среди файлов должен быть `setup.py` в котором содержать инструкции для `setuputils`, как правильно собрать пакет. Мы можем создать дистрибутив sdist, запустив:

```bash
python setup.py sdist 
```

*Напоминание: ранее мы использовали `python setup.py install` для установки*. По умолчанию дистрибутив будет сгенерирован в виде tar-архива (). Другие варианты сжатия можно указать при сборке.

```bash
python setup.py sdist --formats=zip,gztar,bztar,ztar,tar 
```

После установки sdist файл setup.py запускается на хосте, обеспечивая правильную установку этого пакета. Таким образом мы при sdist мы получаем исходные тексты программ, которые собираются на нашей системе. 

Второй тип, `bdist` немного сложнее для разработчика, так как он собирает пакет до того как опубликовать его. Это убирает необходимость собирать пакет на стороне пользователя, так как он уже получит собранные библиотеки (`.pyc`, `.so`, `.dll`) и может использовать его сразу. На данный момент существуют два основных формата распространения для **bdist** [eggs и wheels](https://packaging.python.org/en/latest/discussions/wheel-vs-egg/), более современным считается **wheels**.

```bash
python setup.py bdist_wheel 
```

Преимущества bdist(wheels):

  * меньший объем пакета и более быстрая установка пакетов Python или пакетов с расширениями на языке C.
  * при сборке из исходных файлов (sdist) требует выполнения произвольного кода для сборки (то что записано в setup.py), что может быть не всегда приемлемо с точки зрения безопасности.
  * по умолчанию `pip` пытается поставить  bdist

Помня о том что bdist является предпочтительным для распространения своего пакета, **sdist** также публикуется так как такое распространение позволяет

### Публикуем свой проект в PyPI

Возьмем проект [mtracker](https://github.com/standlab/mtracker) с предыдущего занятия. Переключимся на ветку `pypi_ready`, чтобы не ломать основной код (и конечно еще раз потренируемся с `git`):

```bash
git clone https://github.com/standlab/mtracker.git

git checkout -b pypi_ready
```

Добавим несколько нововведений. Ранее мы не использовали никаких дополнительных библиотек,  `install_requires=[]`. Сейчас мы хотим добавить библиотеку `matplotlib` в зависимости к проекту. Мы будем использовать виртуальное окружение с помощью `pipenv` (подробнее о виртуальных окружения есть отдельный урок). *Настраивать виртуальное окружение всегда полезно, так как это изолируют все специфичные зависимости. У меня на практике был случай когда установка библиотеки напрочь сломало среду разработки Spyder (стандартная среда поставки Anaconda)*.

```bash
sudo apt install pipenv
```
Переходим в папку проекта, если не сделали это ранее `cd ./mtracker` и создаем окружение. 

```bash
pipenv install
```

После этого появятся два новых файла (проверьте через `git status`) `Pipfile` и `Pipfile.lock`. Содержимое `Pipfile` без дополнительных зависимостей выглядит так:

```bash
cat Pipfile

[[source]]
url = "https://pypi.org/simple"
verify_ssl = true
name = "pypi"

[packages]

[dev-packages]

[requires]
python_version = "3.10"
```

Пустой `Pipfile.lock` содержит примерно ту же информацию. Теперь активируем виртуальное окружение и выполним установку `matplotlib`:

```bash
pipenv shell
pipenv install matplotlib
```

И еще раз взглянем на `Pipfile`:

```bash
cat Pipfile
[[source]]
url = "https://pypi.org/simple"
verify_ssl = true
name = "pypi"

[packages]
matplotlib = "*"

[dev-packages]

[requires]
python_version = "3.10"
```

Содержимое `Pipfile.lock` теперь выглядит громоздко, но мы так же видим что там теперь есть информация `matplotlib`, выполнив `cat Pipfile.lock`. Содержится вся необходимая по зависимостям и их версиям.

Теперь мы можем прописать `install_requires` вручную или загрузить из файла:

```python
import json
from os import path

here = path.abspath(path.dirname(__file__))

with open(path.join(here, 'README.rst'), encoding='utf-8') as f:
    long_description = f.read()

def read_dependencies(fname):
    filepath = path.join(here, fname)
    with open(filepath) as piplock:
        content = json.load(piplock)
        return [dependency for dependency in content.get('default')]
```

Так же мы можем выполнить другие операции перед сборкой, которые могут проверить аннотацию типов, форматирование кода, проверить валидность кода, собрать документацию и выполнить тесты. Аннотация типов необязательна для python, но улучшает читаемость кода. Рассмотрим некоторые из них, остальные будем изучать в отдельных уроках. Начнем с форматирование кода. В python общепринятым является оформление согласно [PEP8](https://peps.python.org/pep-0008/). *Примечание: предложение по улучшению языка python [PEP](https://peps.python.org/pep-0000/) (Python Enhancement Proposals) можно считать руководством по  хорошим практикам и подоходом к решению определнных задач, до которых дошло сообщество Python разарботчиков. PEP пронумерованы и PEP8 описывает стиль кода на языке Python*. 

#### Немного о форматировании по PEP8

Здесь мы не будем подробно останавливаться на всех рекомендациях из PEP8, но посмотрим на `autopep8`. Этот инструмента поможет нам скорректировать форматирование, например уберет лишние пробелы или правильно расположит код.

```bash
(base) artem@pc:~/tmp$ cat sample.py 
if foo == 'blah': do_blah_thing()
do_one(); do_two(); do_three()
(base) artem@pc:~/tmp$ autopep8 ./sample.py 
if foo == 'blah':
    do_blah_thing()
do_one()
do_two()
do_three()

```

Не все что написано в PEP8 может быть поправлено автоматически, например `autopep8` не поправит не информативные комментарии. 

```python
# line with not usefull comment 
x = x + 1                 # Increment x

# line with usefull comment 
x = x + 1                 # Compensate for border
```

```bash
(base) artem@pc:~/tmp$ cat sample.py 
x = x + 1         # Increment x
(base) artem@pc:~/tmp$ autopep8 ./sample.py 
x = x + 1         # Increment x
(base) artem@pc:~/tmp$ 
```

#### Возвращаемся в проект.

Установим `autopep8`, но так как это пакет для сборки, не зависимость самого кода, сделаем это с флагом `-d`:

```bash
pipenv install -d autopep8
```

Посмотрим файл Pipfile и увидим, в секции `[dev-packages]` появилась новая строка:

```bash
[dev-packages]
autopep8 = "*"
```

Так же поставим `pytest`:

```bash
pipenv install -d pytest
```

Остальные аспекты пока оставим для дальнейших занятий.

Теперь мы готовы написать Make файл для сборки своего пакета. 

```bash
help:
	@echo "Make project with following instructions"
	@cat Makefile

dev:
	pip install -e .

test: dev
	pytest --doctest-modules --junitxml=junit/test-results.xml

build: clean
	pip install wheel
	python setup.py bdist_wheel

clean:
	@rm -rf .pytest_cache/ .mypy_cache/ junit/ build/ dist/
	@find . -not -path './.venv*' -path '*/__pycache__*' -delete
	@find . -not -path './.venv*' -path '*/*.egg-info*' -delete
```

Указав `test: dev` мы сделали опцию test зависимой от опции dev и поэтому выполниться сначала она и затем test. 

```bash 
pipenv shell 
make test
pip install -e .


pytest --doctest-modules --junitxml=junit/test-results.xml
============================== test session starts ===============================
platform linux -- Python 3.10.9, pytest-7.2.1, pluggy-1.0.0
rootdir: /home/artem/swdev/gitrepo/edu/toolchain_proj/mtracker
collected 1 item                                                                 

test/test_mtracker.py .                                                    [100%]

- generated xml file: /home/artem/swdev/gitrepo/edu/toolchain_proj/mtracker/junit/test-results.xml -
=============================== 1 passed in 0.06s ================================
```


Мы видим что тесты походят и мы готовы собрать наш проект. Сделаем для начала очистку и посмотрим какие файл добавились при сборке.

```bash
make clean
ls
    LICENSE   mtracker  Pipfile.lock  requirements.txt  test
    Makefile  Pipfile   README.md     setup.py
make build 
ls
    build  LICENSE   mtracker           Pipfile       README.md         setup.py
    dist   Makefile  mtracker.egg-info  Pipfile.lock  requirements.txt  test
ls dist
    mtracker-1.0-py3-none-any.whl
```
У нас появилось несколько новых каталогов. И наш собранный пакет расположен в dist. Проверим что mtracker не установлен в нашем окружении, команда ниже ничего не должна вывести.

```bash
pip list | grep mtracker
```
И устанавливаем собранный пакет `mtracker-1.0-py3-none-any.whl`:

```bash
pip install ./dist/*.whl
pip list | grep mtracker
    mtracker         1.0
```



